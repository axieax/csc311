{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/axieax/csc311/blob/main/csc311_pytorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# PyTorch Tutorial"
      ],
      "metadata": {
        "id": "LIG2vBrSHujh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we import and check the version of `torch`."
      ],
      "metadata": {
        "id": "XB6F755yIjcD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOaagFfQIT16",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acf298e8-c808-49c8-caec-dae80c22c1a9"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "\n",
        "import numpy as np\n",
        "from tqdm.notebook import tqdm\n",
        "print(torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A few other useful imports for debugging and visualizations."
      ],
      "metadata": {
        "id": "-tVzMo7MIuvR"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tYICxJUrUjs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9db232a0-107e-4ea0-c85a-548d6d3b8313"
      },
      "source": [
        "!pip install ipdb\n",
        "!pip install torchviz\n",
        "!apt install graphviz\n",
        "import ipdb\n",
        "from torchviz import make_dot"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: ipdb in /usr/local/lib/python3.7/dist-packages (0.13.9)\n",
            "Requirement already satisfied: ipython>=7.17.0 in /usr/local/lib/python3.7/dist-packages (from ipdb) (7.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from ipdb) (57.4.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipdb) (4.4.2)\n",
            "Requirement already satisfied: toml>=0.10.2 in /usr/local/lib/python3.7/dist-packages (from ipdb) (0.10.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (2.6.1)\n",
            "Requirement already satisfied: jedi>=0.16 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.18.1)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (4.8.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (2.0.10)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython>=7.17.0->ipdb) (5.1.1)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.16->ipython>=7.17.0->ipdb) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect>4.3->ipython>=7.17.0->ipdb) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython>=7.17.0->ipdb) (1.15.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torchviz in /usr/local/lib/python3.7/dist-packages (0.0.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.7/dist-packages (from torchviz) (0.10.1)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from torchviz) (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->torchviz) (4.1.1)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "graphviz is already the newest version (2.40.1-2).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 12 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SDGKdlknJMuK"
      },
      "source": [
        "## PyTorch: The Basics\n",
        "\n",
        "PyTorch allows you to dynamically define computational graphs. This is done by operating on PyTorch Tensor objects\n",
        "\n",
        "Here is an example, where we work with the function\n",
        "\n",
        "$$f(x) = x^2 + 2x + 6$$\n",
        "\n",
        "Note how there is nothing special about this function in terms of PyTorch specific syntax, i.e. you could apply this to any object that implements the `**`, `*` and `+` operators."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFyOEjoMIdys"
      },
      "source": [
        "def f(x):\n",
        "    return x ** 2 + 2 * x + 6"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbIIRok6KQ1K"
      },
      "source": [
        "Now let's compute the derivative $$\\frac{d}{dx}\\bigg\\rvert_{x=4} f(x) = 2(4) + 2 = 10$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "65doQHZOIgLL"
      },
      "source": [
        "np_x = np.array([4.0])\n",
        "x = torch.from_numpy(np_x)\n",
        "y = f(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3Ck1PKTKMg6"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrogftWDKNwl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2b641c87-1841-4517-b531-5d0de931ded9"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BD-uTSpZLGdP"
      },
      "source": [
        "What went wrong in the above call to `backward` was that `x` did not have its `requires_grad` property set to true. By default, during the forward pass, i.e. when evaluating f(x), an operation is recorded in the backward graph, only if at least one of its input tensors requires a gradient.\n",
        "\n",
        "Let's set `x.requires_grad = True` and redo the above."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MfsSN6jKH2E"
      },
      "source": [
        "np_x = np.array([4.0])\n",
        "x = torch.from_numpy(np_x).requires_grad_(True)\n",
        "y = f(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rUdJKPjoIzkN"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4h9wf3iW_ZB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03602621-eb5d-49bf-e070-38f69e1d6ce5"
      },
      "source": [
        "print(x.grad)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([10.], dtype=torch.float64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DbwQXFZbTF4H"
      },
      "source": [
        "We can visualize the computation graph by calling the `make_dot` function from `torchviz`. There are \n",
        "\n",
        "* 2 Addition Operations\n",
        "* 1 Power Operation\n",
        "* 1 Multiply Operation\n",
        "* 1 Accumulate Operation\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhYwWghSRwhD"
      },
      "source": [
        "make_dot(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qCWi1fPI1Kj"
      },
      "source": [
        "If we instead evaluate $$\\frac{d}{dx}\\bigg\\rvert_{x=5} f(x) = 2(5) + 2 = 12$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YZtfuqTgI22f"
      },
      "source": [
        "np_x = np.array([5.0])\n",
        "x = torch.from_numpy(np_x).requires_grad_(True)\n",
        "y = f(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ML7UhKGEI-RX"
      },
      "source": [
        "y.backward()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vYaNJ69eJAlm"
      },
      "source": [
        "x.grad"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ySlOO_cXCpom"
      },
      "source": [
        "We still get the right answer.\n",
        "\n",
        "Unlike Tensorflow, we can define the graph on the fly. That is why it is more convenient to define a function in PyTorch: we call the function as part of constructing the graph."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P1H4XJ-uJovy"
      },
      "source": [
        "## Linear Classification with Pytorch\n",
        "\n",
        "Let's now create a simple linear function for classifiying MNIST digits. Material is lifted from: https://github.com/fastai/fastai_old/blob/master/dev_nb/001a_nn_basics.ipynb"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e4lMBUMSYaNy"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6G7YXhJZms1"
      },
      "source": [
        "First we define/download the data. Note that when working with Google colab, whatever data you may have downloaded will eventually be deleted, as will the variables and functions in the runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hWHpTqTIJBZ0"
      },
      "source": [
        "from torchvision import datasets, transforms\n",
        "\n",
        "mnist_train = datasets.MNIST('data', train=True, download=True,\n",
        "                       transform=transforms.ToTensor())\n",
        "\n",
        "mnist_test = datasets.MNIST('../data', train=False, download=True, transform=\n",
        "                            transforms.ToTensor())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_XFXXh4WXBl"
      },
      "source": [
        "print(mnist_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6KUQqN6C7NE"
      },
      "source": [
        "We can easily visualize the images and their corresponding label as below. See how index 0 for a given sample corresponds to the image, and index 1 is the label."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b7wt5b3PX2YW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "326dd592-aa03-4f65-d0e2-9273f48c6c0e"
      },
      "source": [
        "indices = [1, 12000, 344]\n",
        "\n",
        "fig = plt.figure(figsize=(len(indices) * 4, 4))\n",
        "\n",
        "for i, index in enumerate(indices):\n",
        "    ax = fig.add_subplot(1, len(indices), i + 1)\n",
        "    example = mnist_train[index]\n",
        "    ax.imshow(example[0].reshape(28, 28), cmap=plt.cm.gray)\n",
        "    ax.set_title(\"Label: {}\".format(example[1]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-796bba41462f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m12000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m344\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VVqIkU_jxF8X"
      },
      "source": [
        "Pytorch's DataLoader is responsible for managing batches. You can create a DataLoader from any Dataset. DataLoader makes it easier to iterate over batches (it can shuffle and give you the next batch).\n",
        "\n",
        "A drawback of having a `Dataset` wrapped with a `DataLoader` is that the `DataLoader` does not allow indexing. That's why if we want to get a batch from a `DataLoader` without actually iterating over it as part of a loop, we have to convert it to an `Iterator`, and then called the `next` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fN4zzJnmY-XD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "2574101f-c308-4760-8d5b-1fafeeb7671c"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "train_dl = DataLoader(mnist_train, batch_size=100, shuffle=False)\n",
        "\n",
        "dataiter = iter(train_dl)\n",
        "images, labels = dataiter.next()\n",
        "viz = torchvision.utils.make_grid(images, nrow=10, padding = 2).numpy()\n",
        "fig, ax = plt.subplots(figsize= (8,8))\n",
        "ax.imshow(np.transpose(viz, (1,2,0)))\n",
        "ax.set_xticks([])\n",
        "ax.set_yticks([])\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-48cebe988864>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mnist_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nsJe7q95aR0X"
      },
      "source": [
        "Thanks to PyTorch's ability to calculate gradients automatically, we can use any standard Python function (or callable object) as a model! So let's just write a plain matrix multiplication and broadcasted addition to create a simple linear model. We also need an activation function, so we'll write log_softmax and use it. Remember: although PyTorch provides lots of pre-written loss functions, activation functions, and so forth, you can easily write your own using plain Python. PyTorch will even create fast GPU or vectorized CPU code for your function automatically.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y4Q0SMKAejNx"
      },
      "source": [
        "## Model Definition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5awYPvQpaTuw"
      },
      "source": [
        "def log_softmax(x): \n",
        "    return x - x.exp().sum(-1).log().unsqueeze(-1)\n",
        "\n",
        "def model(xb, weights, bias):      \n",
        "    return log_softmax(xb @ weights + bias)\n",
        "\n",
        "def nll(input, target): \n",
        "    # input (prediction) shape = (batch_size, 10)\n",
        "    # target shape = (batch_size,)\n",
        "    # input[range(batch_size), target] shape = (batch_size,)\n",
        "    return -input[range(target.shape[0]), target].mean()\n",
        "\n",
        "def accuracy(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return (preds==yb).float().mean()\n",
        "\n",
        "def num_correct(out, yb):\n",
        "    preds = torch.argmax(out, dim=1)\n",
        "    return torch.sum(preds == yb)\n",
        "\n",
        "loss_func = nll"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAPJAJN6ahSb"
      },
      "source": [
        "In the above, the '@' is syntactic sugar for the matrix multiply operation. The naming of the above functions is a bit misleading. Recall that the cross entropy loss, or negative log-likelihood, is defined as \n",
        "\n",
        "$$-\\sum_{j=1}^{K}y_{j}\\mathrm{log} \\: p_j$$ \n",
        "\n",
        "where $y$ is a one-hot encoded vector containing an entry of 1 at the index of the target class, and 0s elsewhere, and $p$ is a vector of probabilities predicted by our model for each class. In the Python definition of `nll` above, the log has been removed since we are already passing in log-probabilities because we're using the activation function `log_softmax`, so it's written as \n",
        "\n",
        "$$-\\sum_{j=1}^{K}y_{j} p'_j$$ \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lfaz2kA4IlPQ"
      },
      "source": [
        "We will call our function on one batch of data (in this case, 128 images). This is one forward pass. Note that our predictions won't be any better than random at this stage, since we start with random weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v0VxUJoTLeSw"
      },
      "source": [
        "def eval_performance(dl, weights, bias):\n",
        "    total_samples = 0\n",
        "    total_correct = 0\n",
        "\n",
        "    for xb, yb in dl:\n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "\n",
        "        preds = model(xb, weights, bias)\n",
        "        correct = num_correct(preds, yb)\n",
        "\n",
        "        total_correct += correct\n",
        "        total_samples += len(yb)\n",
        "\n",
        "    return total_correct / float(total_samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otufQujremP_"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kx8A9ZmLagtW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "f2522843-5d33-4c98-97cf-bf45f4a8cb30"
      },
      "source": [
        "lr = 0.1\n",
        "epochs = 5\n",
        "bs = 128\n",
        "\n",
        "in_shape = 784\n",
        "out_shape = 10\n",
        "\n",
        "train_dl = DataLoader(mnist_train, batch_size=bs)\n",
        "test_dl = DataLoader(mnist_test, batch_size=bs)\n",
        "\n",
        "# Initialize weights\n",
        "weights = torch.randn(in_shape, out_shape) / math.sqrt(in_shape)\n",
        "weights.requires_grad_()\n",
        "bias = torch.zeros(out_shape, requires_grad=True)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    for i, (xb, yb) in enumerate(train_dl):\n",
        "    \n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "            \n",
        "        # Forward pass    \n",
        "        pred = model(xb, weights, bias)\n",
        "        loss = loss_func(pred, yb)\n",
        "\n",
        "        # Backward pass\n",
        "        loss.backward()\n",
        "        with torch.no_grad():   # temporarily sets all the requires_grad flags to False\n",
        "            weights -= weights.grad * lr\n",
        "            bias -= bias.grad * lr\n",
        "            weights.grad.zero_()\n",
        "            bias.grad.zero_()\n",
        "            \n",
        "    train_acc = eval_performance(train_dl, weights, bias)\n",
        "    test_acc = eval_performance(test_dl, weights, bias)\n",
        "    print(\"Epoch: {} | Train Acc: {} | Test Acc: {}\".format(epoch + 1, train_acc,\n",
        "                                                            test_acc))\n",
        "     \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-708d7100a978>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mout_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_dl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmnist_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'mnist_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lOfK8Q5CeoYe"
      },
      "source": [
        "## Weight Visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KPI_vEbt0qQY"
      },
      "source": [
        "Because the classifer is a linear model, the weight parameters connected to each output class can be viewed as an image as well (28x28, same size as the input). We visualize the weights below. They tell us how the linear classifer weighs the pixels of the input image to make predictions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZLHUDjhXy85h",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "16aae8f6-98fa-40f7-ba2a-71f86c926f77"
      },
      "source": [
        "nrows = 2\n",
        "ncols = 5\n",
        "weights_np = weights.detach().cpu().numpy()\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, )\n",
        "\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        # axes[i, j].imshow(np.maximum(0.0, weights_np[:, i * ncols + j]).reshape((28, 28)), cmap='gray')#plt.cm.coolwarm)\n",
        "        axes[i, j].imshow(weights_np[:, i * ncols + j].reshape((28, 28)), cmap='gray')#plt.cm.coolwarm)\n",
        "        axes[i, j].set_xticks([])\n",
        "        axes[i, j].set_yticks([])\n",
        "        \n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-f26a3eb61ec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mncols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mweights_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'weights' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_H6uUr9Unkdi"
      },
      "source": [
        "The above training loop is a bit clunky and error-prone. Moreover, the code would get very messy if our model is larger and more complicated. In the following example, we will take advantage of Pytorch's built-in functionalities to build more powerful models.\n",
        "\n",
        "## Neural Network with Pytorch\n",
        "\n",
        " We first introduce a helper function for evaluating neural networks."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tnwZNcARdVz9"
      },
      "source": [
        "def get_test_stat(model, dl, device):\n",
        "    model.eval()    # set model to eval mode\n",
        "    cum_loss, cum_acc = 0.0, 0.0\n",
        "    total_samples = 0\n",
        "\n",
        "    for i, (xb, yb) in enumerate(dl):\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        \n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "        y_pred = model(xb)\n",
        "        loss = loss_fn(y_pred, yb)\n",
        "        acc = accuracy(y_pred, yb)\n",
        "        cum_loss += loss.item() * len(yb)\n",
        "        cum_acc += acc.item() * len(yb)\n",
        "        total_samples += len(yb)\n",
        "    \n",
        "    cum_loss /= total_samples\n",
        "    cum_acc /= total_samples\n",
        "    model.train()   # set model back to train mode\n",
        "    return cum_loss, cum_acc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zg-kIf6oijc_"
      },
      "source": [
        "Then, we build a neural network with one hidden layer, by extending the `torch.nn.Module` class. This allows us to keep the code modularized, and is how larger and more complicated models (e.g. ConvNets) are usually built in PyTorch."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N8cvw7UThl4S"
      },
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        # define the parameters here\n",
        "        self.fc = torch.nn.Linear(input_dim, hidden_dim)          # first layer\n",
        "        self.out_layer = torch.nn.Linear(hidden_dim, output_dim)  # output layer\n",
        "    \n",
        "    def forward(self, x):   # defines the forward pass (overwriting the default method)\n",
        "        out = self.fc(x)            # pass input through the first layer\n",
        "        out = F.relu(out)           # apply ReLU activation\n",
        "        out = self.out_layer(out)   # pass through the output layer\n",
        "        \n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o7CKHUqwlCmd"
      },
      "source": [
        "We can now train the network. Note that instead of manually updating the weights ourselves, we use a built-in PyTorch optimizer here `torch.optim.SGD`. Many other optimizers are available too (https://pytorch.org/docs/stable/optim.html)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M2ItDIThddhe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "88a83b12-b6e7-4d7e-880c-794c59d602db"
      },
      "source": [
        "learning_rate = 1e-2\n",
        "epochs = 10\n",
        "\n",
        "dim_x = 784\n",
        "dim_h = 100\n",
        "dim_out = 10\n",
        "\n",
        "# instantiate the model\n",
        "model = Net(dim_x, dim_h, dim_out)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# create datasets and data loader\n",
        "mnist_train = datasets.MNIST('data', train=True, download=True,\n",
        "                       transform=transforms.ToTensor())\n",
        "\n",
        "mnist_test = datasets.MNIST('../data', train=False, download=True, transform=\n",
        "                            transforms.ToTensor())\n",
        "train_dl = DataLoader(mnist_train, batch_size=bs)\n",
        "test_dl = DataLoader(mnist_test, batch_size = 100)\n",
        "\n",
        "# Using GPUs in PyTorch is pretty straightforward\n",
        "if torch.cuda.is_available():\n",
        "    print(\"Using cuda\")\n",
        "    use_cuda = True\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = \"cpu\"\n",
        "\n",
        "model.to(device)\n",
        "loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "# set the model to training mode\n",
        "model.train()\n",
        "\n",
        "train_stats = {\n",
        "    'epoch': [],\n",
        "    'loss': [],\n",
        "    'acc': []\n",
        "}\n",
        "test_stats = {\n",
        "    'epoch': [],\n",
        "    'loss': [],\n",
        "    'acc': []\n",
        "}\n",
        "\n",
        "pbar = tqdm(range(epochs))\n",
        "for epoch in pbar:\n",
        "    pbar.set_description(f\"Epoch {epoch + 1} / 10\")\n",
        "    train_loss = 0.0\n",
        "    train_acc = 0.0\n",
        "    for i, (xb, yb) in enumerate(train_dl):\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        xb = xb.view(xb.size(0), -1)\n",
        "        \n",
        "        # Forward pass\n",
        "        y_pred = model(xb)\n",
        "        loss = loss_fn(y_pred, yb)\n",
        "        acc = accuracy(y_pred, yb)\n",
        "        # Backward pass\n",
        "        model.zero_grad()  # Zero out the previous gradient computation\n",
        "        loss.backward()    # Compute the gradient\n",
        "        optimizer.step()   # Use the gradient information to make a step\n",
        "        train_stats['epoch'].append(epoch + i / len(train_dl))\n",
        "        train_stats['loss'].append(loss.item())\n",
        "        train_stats['acc'].append(acc.item())\n",
        "    \n",
        "    test_loss, test_acc = get_test_stat(model, test_dl, device)\n",
        "    test_stats['epoch'].append(epoch + 1)\n",
        "    test_stats['loss'].append(test_loss)\n",
        "    test_stats['acc'].append(test_acc)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-362993804e54>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# create datasets and data loader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m mnist_train = datasets.MNIST('data', train=True, download=True,\n\u001b[0m\u001b[1;32m     15\u001b[0m                        transform=transforms.ToTensor())\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datasets' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SoEzaOypwZLG"
      },
      "source": [
        "Plot training and test loss & accuracy curves.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ljLJGE8_t3zd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "2028927e-2dea-4e16-e7a9-4725b16bdda2"
      },
      "source": [
        "fig, axes = plt.subplots(nrows=2, ncols=1, figsize=(6, 6))\n",
        "\n",
        "axes[0].plot(train_stats['epoch'], train_stats['loss'], label='train')\n",
        "axes[0].plot(test_stats['epoch'], test_stats['loss'], label='test')\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss')\n",
        "\n",
        "axes[1].plot(train_stats['epoch'], train_stats['acc'], label='train')\n",
        "axes[1].plot(test_stats['epoch'], test_stats['acc'], label='test')\n",
        "axes[1].set_xlabel('Epoch')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-33-8a795386cbf5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_xlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBddFV1gzzxO"
      },
      "source": [
        "## Weight visualization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dw0Ysejq397m"
      },
      "source": [
        "We visualize the learned weights in the first layer of the network as images. Compared to the linear model before, this model has 100 hidden units with ReLU activation, enabling it to make use of a more diverse set of features."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mLEatAmV27uz",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "d43d01fc-7d94-4712-ee42-3f695d9b373d"
      },
      "source": [
        "nrows = 10\n",
        "ncols = 10\n",
        "first_layer_weights = model.fc.weight.detach().cpu().numpy()\n",
        "fig, axes = plt.subplots(nrows=ncols, ncols=ncols, figsize=(6, 6))\n",
        "\n",
        "for i in range(nrows):\n",
        "    for j in range(ncols):\n",
        "        axes[i, j].imshow(first_layer_weights[i * ncols + j].reshape((28, 28)), cmap='gray')\n",
        "        axes[i, j].set_xticks([])\n",
        "        axes[i, j].set_yticks([])\n",
        "        \n",
        "plt.tight_layout(pad=0.1)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-117673b52aab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mncols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mfirst_layer_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mncols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mncols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uPKfs40iFPWX"
      },
      "source": [
        "## [Optional Exercise] What input activates an output class the most?\n",
        "Unlike the linear model, we cannot directly visualize the weights connected to each output class. Instead, we will solve an optimization problem. Specifically, we will:\n",
        "\n",
        "1. Choose an output class you'd like to visualize (e.g. '2'). Initialize the input to be a random image.\n",
        "2. Compute the forward pass through the network.\n",
        "3. Compute the gradient of the output unit w.r.t. the *input*.\n",
        "4. Do a gradient ascent step on the *input*.\n",
        "5. Repeat step 2-4 until a satisfactory visualization is obtained.\n",
        "\n",
        "Optimizing the input to maximize the activation of some feature unit (in this case, an output unit) is a technique for feature visualization. This exercise only gives a naive example, and would probably not produce satisfactory visualizations on larger models and more diverse datasets (e.g. large ConvNet models on ImageNet). See [this article](https://distill.pub/2017/feature-visualization/) for techniques and fun examples of feature visualizations on GoogleNet trained on Imagenet."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RQTnjBY0KNu-"
      },
      "source": [
        "input_lr = 0.01\n",
        "input_train_itr = 200\n",
        "\n",
        "fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(6, 3))\n",
        "pbar = tqdm(range(10))\n",
        "\n",
        "\n",
        "for class_i in pbar:\n",
        "    pbar.set_description(f\"Visualizing class '{class_i}'\")\n",
        "\n",
        "    # 1. Initialize the input image.\n",
        "    ### YOUR CODE HERE ###\n",
        "    input_img = torch.normal(mean=torch.zeros((784,)), std=0.001).to(device)\n",
        "\n",
        "    # we need to do optimization on imput_img, hence set the requires_grad flag\n",
        "    input_img.requires_grad = True\n",
        "\n",
        "    # define the gradient descent optimizer on input_img\n",
        "    input_optim = torch.optim.SGD([input_img], lr=input_lr)\n",
        "\n",
        "    for train_i in range(input_train_itr):\n",
        "        # 2. Compute the forward pass through the network.\n",
        "        ### YOUR CODE HERE ###\n",
        "        model_out = model(input_img)\n",
        "        neg_output = -1 * model_out[class_i]\n",
        "\n",
        "        # 3. backward pass\n",
        "        ### YOUR CODE HERE ###\n",
        "        input_optim.zero_grad()       \n",
        "        neg_output.backward()\n",
        "\n",
        "        # 4. Do a gradient ascent step on the input\n",
        "        ### YOUR CODE HERE ###\n",
        "        input_optim.step()\n",
        "\n",
        "    # plot the optimized input_img\n",
        "    axes[class_i // 5, class_i % 5].imshow(input_img.detach().cpu().numpy().reshape((28, 28)), cmap='gray')\n",
        "    axes[class_i // 5, class_i % 5].set_xticks([])\n",
        "    axes[class_i // 5, class_i % 5].set_yticks([])\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}